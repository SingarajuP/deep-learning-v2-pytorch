{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 8 - Transfer Learning (Exercises).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agungsantoso/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/Part%208%20-%20Transfer%20Learning%20(Exercises).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "O-dYBcFO8BRI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "\n",
        "In this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision. Specifically, you'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
        "\n",
        "ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep neural networks using an architecture called convolutional layers. I'm not going to get into the details of convolutional networks here, but if you want to learn more about them, please [watch this](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
        "\n",
        "Once trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
        "\n",
        "With `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now."
      ]
    },
    {
      "metadata": {
        "id": "JiHyJqzC8RMu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCy3B_oNkNe3",
        "colab_type": "code",
        "outputId": "f98a3c98-db29-4954-df94-b99b4b1cbc2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip;\n",
        "!unzip -qq Cat_Dog_data.zip;\n",
        "!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-26 01:10:27--  https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.237.13\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.237.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580495262 (554M) [application/zip]\n",
            "Saving to: ‘Cat_Dog_data.zip’\n",
            "\n",
            "Cat_Dog_data.zip    100%[===================>] 553.60M  19.9MB/s    in 33s     \n",
            "\n",
            "2018-11-26 01:11:00 (16.7 MB/s) - ‘Cat_Dog_data.zip’ saved [580495262/580495262]\n",
            "\n",
            "--2018-11-26 01:11:12--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2813 (2.7K) [text/plain]\n",
            "Saving to: ‘helper.py’\n",
            "\n",
            "helper.py           100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-11-26 01:11:12 (41.8 MB/s) - ‘helper.py’ saved [2813/2813]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6LzBoEk_kQYH",
        "colab_type": "code",
        "outputId": "aedbd0d4-3a63-42af-a1e3-498c87f1ad72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0\n",
        "!pip install PIL\n",
        "!pip install image\n",
        "import PIL"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n",
            "Collecting PIL\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
            "Collecting image\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ec/51969468a8b87f631cc0e60a6bf1e5f6eec8ef3fd2ee45dc760d5a93b82a/image-1.5.27-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n",
            "Collecting django (from image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/e5/2676be45ea49cfd09a663f289376b3888accd57ff06c953297bfdee1fb08/Django-2.1.3-py3-none-any.whl (7.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 7.3MB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.7)\n",
            "Installing collected packages: django, image\n",
            "Successfully installed django-2.1.3 image-1.5.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nofmqxmb8BRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "import helper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqnTusKn8BRQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`."
      ]
    },
    {
      "metadata": {
        "id": "3GdrVRno8BRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'Cat_Dog_data'\n",
        "\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTsV13F68BRU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "FRIJik8f8BRW",
        "colab_type": "code",
        "outputId": "0930e0fa-61bc-4444-a997-04e5d3dcc54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8907
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.densenet121(pretrained=True)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.torch/models/densenet121-a639ec97.pth\n",
            "100%|██████████| 32342954/32342954 [00:00<00:00, 54391859.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "-w5bIpWO8BRa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."
      ]
    },
    {
      "metadata": {
        "id": "yx_qIe8s8BRb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8h7dek7I8BRe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n",
        "\n",
        "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU."
      ]
    },
    {
      "metadata": {
        "id": "rRBNvb0b8BRf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mxGrpVtF8BRi",
        "colab_type": "code",
        "outputId": "cf7f2cfa-56ef-442c-8ef9-fac45dc63f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "for device in ['cpu', 'cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        # Move input and label tensors to the GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ii==3:\n",
        "            break\n",
        "        \n",
        "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cpu; Time per batch: 6.905 seconds\n",
            "Device = cuda; Time per batch: 0.018 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GzHKeKTj8BRm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
        "```python\n",
        "# at beginning of the script\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "...\n",
        "\n",
        "# then whenever you get a new Tensor or Module\n",
        "# this won't copy if they are already on the desired device\n",
        "input = data.to(device)\n",
        "model = MyModule(...).to(device)\n",
        "```\n",
        "\n",
        "From here, I'll let you finish training the model. The process is the same as before except now your model is much more powerful. You should get better than 95% accuracy easily.\n",
        "\n",
        ">**Exercise:** Train a pretrained models to classify the cat and dog images. Continue with the DenseNet model, or try ResNet, it's also a good model to try out first. Make sure you are only training the classifier and the parameters for the features part are frozen."
      ]
    },
    {
      "metadata": {
        "id": "bWvZ3l4w8BRo",
        "colab_type": "code",
        "outputId": "06bda27b-faf5-47a7-8764-6e10faaeefa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8978
        }
      },
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# Freeze parameters so don't backprop\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "  \n",
        "model.classifier = nn.Sequential(\n",
        "  nn.Linear(1024, 256),\n",
        "  nn.ReLU(),\n",
        "  nn.Dropout(0.2),\n",
        "  nn.Linear(256, 2),\n",
        "  nn.LogSoftmax(dim=1)\n",
        ")\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Only train classifier parameters\n",
        "optimzer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2)\n",
              "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
              "    (4): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "3kBQa97D_3O-",
        "colab_type": "code",
        "outputId": "8665a803-421f-4380-ca8c-911cd2f02a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6212
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for inputs, labels in trainloader:\n",
        "    steps += 1\n",
        "    # Move input and label tensors to default device\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    logps = model.forward(inputs)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    \n",
        "    if steps % print_every == 0:\n",
        "      test_loss = 0\n",
        "      accuracy = 0\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          logps = model.forward(inputs)\n",
        "          batch_loss = criterion(logps, labels)\n",
        "          \n",
        "          test_loss += batch_loss.item()\n",
        "          \n",
        "          # Calculate accuracy\n",
        "          ps = torch.exp(logps)\n",
        "          top_p, top_class = ps.topk(1, dim=1)\n",
        "          equals = top_class == labels.view(*top_class.shape)\n",
        "          accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "          \n",
        "      print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "            f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "            f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "            f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "      \n",
        "      running_loss = 0\n",
        "      model.train()\n",
        "          "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1.. Train loss: 0.708.. Test loss: 0.727.. Test accuracy: 0.330\n",
            "Epoch 1/1.. Train loss: 0.692.. Test loss: 0.726.. Test accuracy: 0.337\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.725.. Test accuracy: 0.342\n",
            "Epoch 1/1.. Train loss: 0.735.. Test loss: 0.724.. Test accuracy: 0.344\n",
            "Epoch 1/1.. Train loss: 0.699.. Test loss: 0.724.. Test accuracy: 0.346\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.723.. Test accuracy: 0.353\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.722.. Test accuracy: 0.355\n",
            "Epoch 1/1.. Train loss: 0.740.. Test loss: 0.722.. Test accuracy: 0.357\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.721.. Test accuracy: 0.361\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.720.. Test accuracy: 0.365\n",
            "Epoch 1/1.. Train loss: 0.727.. Test loss: 0.721.. Test accuracy: 0.367\n",
            "Epoch 1/1.. Train loss: 0.701.. Test loss: 0.721.. Test accuracy: 0.364\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.721.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.721.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.367\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.364\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.720.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.732.. Test loss: 0.720.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.748.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.739.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.721.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.721.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.711.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.707.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.744.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.732.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.735.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.721.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.721.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.721.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.721.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.745.. Test loss: 0.721.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.721.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.721.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.701.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.701.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.719.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.732.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.703.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.739.. Test loss: 0.719.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.719.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.740.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.727.. Test loss: 0.719.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.704.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.721.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.721.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.727.. Test loss: 0.721.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.722.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.721.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.721.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.743.. Test loss: 0.721.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.721.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.720.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.745.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.749.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.721.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.721.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.702.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.706.. Test loss: 0.721.. Test accuracy: 0.362\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.722.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.707.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.721.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.736.. Test loss: 0.721.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.721.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.721.. Test accuracy: 0.367\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.721.. Test accuracy: 0.365\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.721.. Test accuracy: 0.364\n",
            "Epoch 1/1.. Train loss: 0.697.. Test loss: 0.721.. Test accuracy: 0.367\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.742.. Test loss: 0.719.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.702.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.720.. Test accuracy: 0.365\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.720.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.710.. Test loss: 0.720.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.721.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.704.. Test loss: 0.721.. Test accuracy: 0.367\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.721.. Test accuracy: 0.362\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.722.. Test accuracy: 0.363\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.721.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.721.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.721.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.711.. Test loss: 0.720.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.720.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.704.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.735.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.719.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.743.. Test loss: 0.719.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.719.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.719.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.753.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.720.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.719.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.712.. Test loss: 0.719.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.703.. Test loss: 0.720.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.737.. Test loss: 0.720.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.727.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.694.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.740.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.721.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.727.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.704.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.702.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.710.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.674.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.707.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.703.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.710.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.733.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.711.. Test loss: 0.720.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.733.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.734.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.709.. Test loss: 0.719.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.720.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.735.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.736.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.697.. Test loss: 0.721.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.721.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.719.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.704.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.720.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.703.. Test loss: 0.721.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.722.. Test accuracy: 0.365\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.721.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.721.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.721.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.700.. Test loss: 0.721.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.710.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.721.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.721.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.711.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.720.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.719.. Test accuracy: 0.383\n",
            "Epoch 1/1.. Train loss: 0.739.. Test loss: 0.720.. Test accuracy: 0.382\n",
            "Epoch 1/1.. Train loss: 0.699.. Test loss: 0.719.. Test accuracy: 0.382\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.709.. Test loss: 0.719.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.719.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.719.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.719.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.736.. Test loss: 0.719.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.711.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.719.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.676.. Test loss: 0.719.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.719.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.709.. Test loss: 0.719.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.704.. Test loss: 0.719.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.710.. Test loss: 0.719.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.736.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.719.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.719.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.712.. Test loss: 0.719.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.719.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.732.. Test loss: 0.719.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.708.. Test loss: 0.719.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.719.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.719.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.701.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.748.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.712.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.745.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.720.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.735.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.721.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.688.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.694.. Test loss: 0.721.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.734.. Test loss: 0.721.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.727.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.721.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.743.. Test loss: 0.721.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.706.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.721.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.712.. Test loss: 0.721.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.720.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.739.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.713.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.720.. Test accuracy: 0.367\n",
            "Epoch 1/1.. Train loss: 0.733.. Test loss: 0.720.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.715.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.711.. Test loss: 0.720.. Test accuracy: 0.367\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.720.. Test accuracy: 0.365\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.721.. Test accuracy: 0.364\n",
            "Epoch 1/1.. Train loss: 0.716.. Test loss: 0.721.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.721.. Test accuracy: 0.369\n",
            "Epoch 1/1.. Train loss: 0.712.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.702.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.719.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.727.. Test loss: 0.719.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.719.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.732.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.719.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.711.. Test loss: 0.719.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.720.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.720.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.697.. Test loss: 0.720.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.720.. Test accuracy: 0.365\n",
            "Epoch 1/1.. Train loss: 0.741.. Test loss: 0.720.. Test accuracy: 0.368\n",
            "Epoch 1/1.. Train loss: 0.697.. Test loss: 0.721.. Test accuracy: 0.362\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.363\n",
            "Epoch 1/1.. Train loss: 0.710.. Test loss: 0.721.. Test accuracy: 0.362\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.721.. Test accuracy: 0.364\n",
            "Epoch 1/1.. Train loss: 0.747.. Test loss: 0.721.. Test accuracy: 0.363\n",
            "Epoch 1/1.. Train loss: 0.755.. Test loss: 0.721.. Test accuracy: 0.365\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.721.. Test accuracy: 0.366\n",
            "Epoch 1/1.. Train loss: 0.736.. Test loss: 0.721.. Test accuracy: 0.363\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.721.. Test accuracy: 0.370\n",
            "Epoch 1/1.. Train loss: 0.706.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.732.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.720.. Test accuracy: 0.371\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.719.. Test accuracy: 0.382\n",
            "Epoch 1/1.. Train loss: 0.702.. Test loss: 0.719.. Test accuracy: 0.382\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.719.. Test accuracy: 0.382\n",
            "Epoch 1/1.. Train loss: 0.733.. Test loss: 0.719.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.719.. Test accuracy: 0.383\n",
            "Epoch 1/1.. Train loss: 0.720.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.719.. Test accuracy: 0.382\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.719.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.719.. Test loss: 0.718.. Test accuracy: 0.384\n",
            "Epoch 1/1.. Train loss: 0.717.. Test loss: 0.719.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.712.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.731.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.723.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.707.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.727.. Test loss: 0.719.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.719.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.735.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.726.. Test loss: 0.719.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.372\n",
            "Epoch 1/1.. Train loss: 0.745.. Test loss: 0.719.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.714.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.721.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.725.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.732.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.710.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.729.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.373\n",
            "Epoch 1/1.. Train loss: 0.718.. Test loss: 0.720.. Test accuracy: 0.374\n",
            "Epoch 1/1.. Train loss: 0.702.. Test loss: 0.720.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.697.. Test loss: 0.719.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.719.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.722.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.728.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.712.. Test loss: 0.720.. Test accuracy: 0.377\n",
            "Epoch 1/1.. Train loss: 0.694.. Test loss: 0.720.. Test accuracy: 0.378\n",
            "Epoch 1/1.. Train loss: 0.693.. Test loss: 0.720.. Test accuracy: 0.380\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.719.. Test accuracy: 0.381\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.720.. Test accuracy: 0.376\n",
            "Epoch 1/1.. Train loss: 0.709.. Test loss: 0.720.. Test accuracy: 0.375\n",
            "Epoch 1/1.. Train loss: 0.730.. Test loss: 0.719.. Test accuracy: 0.379\n",
            "Epoch 1/1.. Train loss: 0.724.. Test loss: 0.719.. Test accuracy: 0.386\n",
            "Epoch 1/1.. Train loss: 0.712.. Test loss: 0.720.. Test accuracy: 0.384\n",
            "Epoch 1/1.. Train loss: 0.738.. Test loss: 0.720.. Test accuracy: 0.383\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}